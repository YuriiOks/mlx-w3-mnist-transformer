{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• PyTorch vs MLX: MNIST ViT Speed Benchmark üöÄ‚è±Ô∏è (v2 - Granular Cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Goal:** Compare forward pass and training step speed for Phase 1 MNIST ViT in PyTorch vs MLX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Visualization & Progress\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim_torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "# MLX Libraries\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn_mlx\n",
    "import mlx.optimizers as optim_mlx\n",
    "from mlx.utils import tree_flatten\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Path & Utilities Setup üìÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Adding project root to sys.path: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer\n",
      "‚öôÔ∏è  Configuring Backprop Bunch logging...\n",
      "  Logger 'Backprop Bunch' level set to: INFO\n",
      "  ‚úÖ File handler added: logs/mnist_vit_train.log\n",
      "  üé® Applying colored formatter to console handler.\n",
      "  ‚úÖ Console handler added.\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [logging.py:135] | \u001b[32müéâ Logging system initialized!\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [440354808.py:10] | \u001b[32m‚úÖ Project utilities loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Add project root to sys.path\n",
    "project_root = Path(os.getcwd()).parent \n",
    "if str(project_root) not in sys.path:\n",
    "    print(f\"üìÇ Adding project root to sys.path: {project_root}\")\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project utilities\n",
    "try:\n",
    "    from utils import logger, load_config, get_device\n",
    "    logger.info(\"‚úÖ Project utilities loaded.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing project utilities: {e}\")\n",
    "    import logging; logger = logging.getLogger(\"Benchmark\")\n",
    "    logging.basicConfig(level=logging.INFO); logger.info(\"Using fallback logger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration & Model Paths ‚öôÔ∏èüíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [2803633295.py:11] | \u001b[32mPyTorch Model Path: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/models/mnist_vit/PyTorch_Phase1_E15_LR0.001_B256_ViT/model_final.pth\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [2803633295.py:12] | \u001b[32mMLX Model Path: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/models/mnist_vit/MLX_Phase1_E15_LR0.001_B256_ViT/model_weights.safetensors\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [run_utils.py:22] | \u001b[32müîç Loading configuration from: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/config.yaml\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [run_utils.py:26] | \u001b[32m‚úÖ Configuration loaded successfully.\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [2803633295.py:32] | \u001b[32mUsing Model Config: Depth=4, Embed=64, Heads=4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- TODO: UPDATE THESE RUN NAMES IF NEEDED ---\n",
    "PYTORCH_RUN_NAME = \"PyTorch_Phase1_E15_LR0.001_B256_ViT\" # Your successful PT run\n",
    "MLX_RUN_NAME = \"MLX_Phase1_E15_LR0.001_B256_ViT\"     # Your successful MLX run\n",
    "# --- End Update --- \n",
    "\n",
    "MODEL_BASE_DIR = project_root / \"models/mnist_vit\"\n",
    "PYTORCH_MODEL_PATH = MODEL_BASE_DIR / PYTORCH_RUN_NAME / \"model_final.pth\"\n",
    "MLX_MODEL_PATH = MODEL_BASE_DIR / MLX_RUN_NAME / \"model_weights.safetensors\"\n",
    "CONFIG_PATH = project_root / \"config.yaml\"\n",
    "\n",
    "logger.info(f\"PyTorch Model Path: {PYTORCH_MODEL_PATH}\")\n",
    "logger.info(f\"MLX Model Path: {MLX_MODEL_PATH}\")\n",
    "\n",
    "# --- Load Config --- \n",
    "config = load_config(config_path=CONFIG_PATH)\n",
    "if config is None: raise FileNotFoundError(\"Config not found!\")\n",
    "\n",
    "# --- Get Phase 1 Params --- \n",
    "model_cfg = config.get('model', {})\n",
    "dataset_cfg = config.get('dataset', {})\n",
    "\n",
    "p1_img_size = dataset_cfg.get('image_size', 28)\n",
    "p1_patch_size = dataset_cfg.get('patch_size', 7)\n",
    "p1_in_channels = dataset_cfg.get('in_channels', 1)\n",
    "p1_num_classes = dataset_cfg.get('num_classes', 10)\n",
    "p1_embed_dim = model_cfg.get('embed_dim', 64)\n",
    "p1_depth = model_cfg.get('depth', 4) # CRITICAL: Ensure this is 4!\n",
    "p1_num_heads = model_cfg.get('num_heads', 4)\n",
    "p1_mlp_ratio = model_cfg.get('mlp_ratio', 2.0)\n",
    "p1_num_outputs = 1 # Phase 1\n",
    "\n",
    "logger.info(f\"Using Model Config: Depth={p1_depth}, Embed={p1_embed_dim}, Heads={p1_num_heads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Device Setup üíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [device_setup.py:38] | \u001b[32m‚úÖ MPS device found and available (Built: True). Selecting MPS.\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [device_setup.py:50] | \u001b[32m‚ú® Selected compute device: MPS\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [4064283489.py:3] | \u001b[32mPyTorch Device: mps\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [4064283489.py:7] | \u001b[32mMLX Default Device: Device(gpu, 0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# PyTorch device setup\n",
    "pt_device = get_device()\n",
    "logger.info(f\"PyTorch Device: {pt_device}\")\n",
    "\n",
    "# MLX default device \n",
    "mlx_device = mx.default_device()\n",
    "logger.info(f\"MLX Default Device: {mlx_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load PyTorch Model üß†pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Adding project root to sys.path: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/notebooks\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [model.py:120] | \u001b[32müß† ViT initialized: img=28, patch=7, depth=4, heads=4, embed=64, outputs=1\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1827731871.py:9] | \u001b[32mLoading PyTorch weights from /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/models/mnist_vit/PyTorch_Phase1_E15_LR0.001_B256_ViT/model_final.pth\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1827731871.py:14] | \u001b[32m‚úÖ PyTorch model loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.mnist_transformer.model import VisionTransformer as VisionTransformerPT\n",
    "\n",
    "model_pt = VisionTransformerPT(\n",
    "    img_size=p1_img_size, patch_size=p1_patch_size, in_channels=p1_in_channels,\n",
    "    num_classes=p1_num_classes, embed_dim=p1_embed_dim, depth=p1_depth,\n",
    "    num_heads=p1_num_heads, mlp_ratio=p1_mlp_ratio, num_outputs=p1_num_outputs\n",
    ")\n",
    "if PYTORCH_MODEL_PATH.exists():\n",
    "    logger.info(f\"Loading PyTorch weights from {PYTORCH_MODEL_PATH}\")\n",
    "    try:\n",
    "        model_pt.load_state_dict(torch.load(PYTORCH_MODEL_PATH, map_location=pt_device))\n",
    "        model_pt.to(pt_device)\n",
    "        model_pt.eval()\n",
    "        logger.info(\"‚úÖ PyTorch model loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error loading PyTorch weights: {e}\")\n",
    "        model_pt = None\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è PyTorch checkpoint not found: {PYTORCH_MODEL_PATH}\")\n",
    "    model_pt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load MLX Model üß†mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [model_mlx.py:108] | \u001b[32müß† VisionTransformerMLX initialized: depth=4, heads=4, embed_dim=64, num_outputs=1\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [3353289622.py:9] | \u001b[32mLoading MLX weights from /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/models/mnist_vit/MLX_Phase1_E15_LR0.001_B256_ViT/model_weights.safetensors\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [3353289622.py:14] | \u001b[32m‚úÖ MLX model loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.mnist_transformer_mlx.model_mlx import VisionTransformerMLX\n",
    "\n",
    "model_mlx = VisionTransformerMLX(\n",
    "    img_size=p1_img_size, patch_size=p1_patch_size, in_channels=p1_in_channels,\n",
    "    num_classes=p1_num_classes, embed_dim=p1_embed_dim, depth=p1_depth,\n",
    "    num_heads=p1_num_heads, mlp_ratio=p1_mlp_ratio # Removed num_outputs\n",
    ")\n",
    "if MLX_MODEL_PATH.exists():\n",
    "    logger.info(f\"Loading MLX weights from {MLX_MODEL_PATH}\")\n",
    "    try:\n",
    "        model_mlx.load_weights(str(MLX_MODEL_PATH))\n",
    "        mx.eval(model_mlx.parameters()) \n",
    "        model_mlx.eval()\n",
    "        logger.info(\"‚úÖ MLX model loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to load MLX weights: {e}\", exc_info=True)\n",
    "        model_mlx = None\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è MLX checkpoint not found: {MLX_MODEL_PATH}\")\n",
    "    model_mlx = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Benchmark Data Batch üî¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [dataset.py:86] | \u001b[32müíæ Loading MNIST Test dataset...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [dataset.py:87] | \u001b[32m   Data directory: /Users/Oks_WORKSPACE/Desktop/DEV/W3_project/mlx-w3-mnist-transformer/data\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [dataset.py:89] | \u001b[32m   Augmentation: Disabled (Test Set)\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [dataset.py:98] | \u001b[32m‚úÖ MNIST Test dataset loaded successfully (10000 samples).\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [3631261467.py:11] | \u001b[32mLoaded PyTorch test batch: Images=torch.Size([256, 1, 28, 28]), Labels=torch.Size([256])\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [3631261467.py:23] | \u001b[32mCreated MLX test batch: Images=(256, 28, 28, 1), Labels=(256,)\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [3631261467.py:28] | \u001b[32mMoved PyTorch batch to target device.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.mnist_transformer.dataset import get_mnist_dataset, MNIST_MEAN, MNIST_STD\n",
    "\n",
    "BENCHMARK_BATCH_SIZE = 256 \n",
    "\n",
    "images_pt = labels_pt = images_mlx = labels_mlx = None \n",
    "\n",
    "test_dataset_pt = get_mnist_dataset(train=False, use_augmentation=False)\n",
    "if test_dataset_pt:\n",
    "    test_loader_pt = DataLoader(test_dataset_pt, batch_size=BENCHMARK_BATCH_SIZE, shuffle=False)\n",
    "    images_pt_cpu, labels_pt_cpu = next(iter(test_loader_pt))\n",
    "    logger.info(f\"Loaded PyTorch test batch: Images={images_pt_cpu.shape}, Labels={labels_pt_cpu.shape}\")\n",
    "    \n",
    "    # --- Prepare MLX data --- \n",
    "    mean_pt = torch.tensor(MNIST_MEAN)\n",
    "    std_pt = torch.tensor(MNIST_STD)\n",
    "    images_pt_unnorm = images_pt_cpu * std_pt[:, None, None] + mean_pt[:, None, None]\n",
    "    images_np_unnorm_0_1 = torch.clamp(images_pt_unnorm, 0, 1).numpy()\n",
    "    images_np_ch_last = np.transpose(images_np_unnorm_0_1, (0, 2, 3, 1))\n",
    "    images_np_mlx_norm = (images_np_ch_last - MNIST_MEAN) / MNIST_STD\n",
    "    images_mlx = mx.array(images_np_mlx_norm.astype(np.float32))\n",
    "    labels_mlx = mx.array(labels_pt_cpu.numpy().astype(np.uint32))\n",
    "    mx.eval(images_mlx, labels_mlx) \n",
    "    logger.info(f\"Created MLX test batch: Images={images_mlx.shape}, Labels={labels_mlx.shape}\")\n",
    "    \n",
    "    # --- Prepare PyTorch data --- \n",
    "    images_pt = images_pt_cpu.to(pt_device)\n",
    "    labels_pt = labels_pt_cpu.to(pt_device)\n",
    "    logger.info(\"Moved PyTorch batch to target device.\")\n",
    "else:\n",
    "    logger.error(\"‚ùå Failed to load MNIST test data for benchmark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define Benchmark Functions ‚è±Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define benchmark_forward --- \n",
    "def benchmark_forward(model, data, device, framework_name, num_runs=100, warmup_runs=10):\n",
    "    \"\"\"Benchmarks inference speed (forward pass). ‚è±Ô∏è\"\"\"\n",
    "    logger.info(f\"‚è±Ô∏è Benchmarking FORWARD pass ({framework_name} on {device})...\")\n",
    "    if model is None or data is None: logger.error(\"‚ùå Model or data missing.\"); return None\n",
    "    times = []\n",
    "    logger.info(f\"  üî• Performing {warmup_runs} warmup runs...\")\n",
    "    # Warmup\n",
    "    if framework_name == \"PyTorch\":\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warmup_runs): _ = model(data)\n",
    "            if device.type == 'cuda': torch.cuda.synchronize()\n",
    "            elif device.type == 'mps': torch.mps.synchronize()\n",
    "    elif framework_name == \"MLX\":\n",
    "         for _ in range(warmup_runs): mx.eval(model(data))\n",
    "    # Benchmark\n",
    "    logger.info(f\"  üöÄ Performing {num_runs} benchmark runs...\")\n",
    "    if framework_name == \"PyTorch\":\n",
    "        with torch.no_grad():\n",
    "            for _ in tqdm(range(num_runs), desc=\"PT Forward\", leave=False):\n",
    "                start_time = time.perf_counter(); _ = model(data)\n",
    "                if device.type == 'cuda': torch.cuda.synchronize()\n",
    "                elif device.type == 'mps': torch.mps.synchronize()\n",
    "                end_time = time.perf_counter(); times.append(end_time - start_time)\n",
    "    elif framework_name == \"MLX\":\n",
    "        for _ in tqdm(range(num_runs), desc=\"MLX Forward\", leave=False):\n",
    "            start_time = time.perf_counter(); mx.eval(model(data))\n",
    "            end_time = time.perf_counter(); times.append(end_time - start_time)\n",
    "    # Results\n",
    "    if not times: logger.error(\"‚ùå No benchmark times recorded.\"); return None\n",
    "    avg_time_ms = np.mean(times) * 1000; std_time_ms = np.std(times) * 1000\n",
    "    logger.info(f\"‚úÖ {framework_name} Forward Avg Time: {avg_time_ms:.3f} ¬± {std_time_ms:.3f} ms\")\n",
    "    return avg_time_ms, std_time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [745493825.py:15] | \u001b[32m‚úÖ Defined MLX loss_and_grad function for benchmark.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Define MLX Loss and Grad Function Needed by Training Benchmark --- \n",
    "loss_and_grad_fn_mlx = None \n",
    "if 'model_mlx' in locals() and model_mlx is not None:\n",
    "    def loss_fn_mlx(model, img, lbl):\n",
    "        logits = model(img)\n",
    "        num_classes = logits.shape[-1]\n",
    "        # Assuming Phase 1 shapes for benchmark\n",
    "        if logits.ndim != 2 or lbl.ndim != 1:\n",
    "             logger.error(f\"‚ùå Unexpected shapes in loss_fn_mlx: {logits.shape}, {lbl.shape}\")\n",
    "             return mx.array(0.0)\n",
    "        loss = mx.mean(nn_mlx.losses.cross_entropy(logits, lbl))\n",
    "        return loss\n",
    "    try:\n",
    "        loss_and_grad_fn_mlx = nn_mlx.value_and_grad(model_mlx, loss_fn_mlx)\n",
    "        logger.info(\"‚úÖ Defined MLX loss_and_grad function for benchmark.\")\n",
    "    except Exception as e_grad:\n",
    "         logger.error(f\"‚ùå Failed to create MLX value_and_grad function: {e_grad}\")\n",
    "         loss_and_grad_fn_mlx = None\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è MLX model not loaded, cannot define loss_and_grad function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define benchmark_train_step --- \n",
    "def benchmark_train_step(\n",
    "    model, data, labels, criterion, optimizer, device, framework_name,\n",
    "    mlx_grad_fn = None, num_runs=50, warmup_runs=5\n",
    "    ):\n",
    "    \"\"\"Benchmarks a single training step (fwd+loss+bwd+step). ‚è±Ô∏è\"\"\"\n",
    "    logger.info(f\"‚è±Ô∏è Benchmarking TRAIN step ({framework_name} on {device})...\")\n",
    "    # Check components\n",
    "    components_missing = model is None or data is None or labels is None or optimizer is None\n",
    "    if framework_name == \"PyTorch\" and criterion is None: components_missing = True; logger.error(\"‚ùå Missing criterion for PyTorch.\")\n",
    "    if framework_name == \"MLX\" and mlx_grad_fn is None: components_missing = True; logger.error(\"‚ùå Missing mlx_grad_fn for MLX.\")\n",
    "    if components_missing: logger.error(\"‚ùå Missing essential components.\"); return None\n",
    "\n",
    "    times = []\n",
    "    if framework_name == \"PyTorch\": model.train()\n",
    "    elif framework_name == \"MLX\": model.train()\n",
    "\n",
    "    # Warmup Runs\n",
    "    logger.info(f\"  üî• Performing {warmup_runs} warmup runs...\")\n",
    "    if framework_name == \"PyTorch\":\n",
    "        for _ in range(warmup_runs):\n",
    "            optimizer.zero_grad(); outputs = model(data); loss = criterion(outputs, labels); loss.backward(); optimizer.step()\n",
    "        if device.type == 'cuda': torch.cuda.synchronize()\n",
    "        elif device.type == 'mps': torch.mps.synchronize()\n",
    "    elif framework_name == \"MLX\":\n",
    "        for i in range(warmup_runs):\n",
    "            try:\n",
    "                 # Get loss and grads\n",
    "                (loss, _), grads = mlx_grad_fn(model, data, labels) # Using _ for accuracy as it's not needed\n",
    "                # Update\n",
    "                optimizer.update(model, grads)\n",
    "                # Evaluate \n",
    "                mx.eval(model.parameters(), optimizer.state)\n",
    "            except Exception as e_warmup:\n",
    "                logger.error(f\"‚ùå Error during MLX warmup run {i}: {e_warmup}\", exc_info=True)\n",
    "                return None # Stop benchmark if warmup fails\n",
    "\n",
    "    # Benchmark Runs\n",
    "    logger.info(f\"  üöÄ Performing {num_runs} benchmark runs...\")\n",
    "    if framework_name == \"PyTorch\":\n",
    "         for _ in tqdm(range(num_runs), desc=\"PT Train Step\", leave=False):\n",
    "            start_time = time.perf_counter(); optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(data); loss = criterion(outputs, labels); loss.backward(); optimizer.step()\n",
    "            if device.type == 'cuda': torch.cuda.synchronize()\n",
    "            elif device.type == 'mps': torch.mps.synchronize()\n",
    "            end_time = time.perf_counter(); times.append(end_time - start_time)\n",
    "    elif framework_name == \"MLX\":\n",
    "        for _ in tqdm(range(num_runs), desc=\"MLX Train Step\", leave=False):\n",
    "            start_time = time.perf_counter()\n",
    "            try:\n",
    "                (loss, _), grads = mlx_grad_fn(model, data, labels)\n",
    "                optimizer.update(model, grads)\n",
    "                mx.eval(model.parameters(), optimizer.state)\n",
    "                end_time = time.perf_counter(); times.append(end_time - start_time)\n",
    "            except Exception as e_bench:\n",
    "                logger.error(f\"‚ùå Error during MLX benchmark run: {e_bench}\", exc_info=True)\n",
    "                return None # Stop benchmark if a run fails\n",
    "\n",
    "    # Results\n",
    "    if not times: logger.error(\"‚ùå No benchmark times recorded.\"); return None\n",
    "    avg_time_ms = np.mean(times) * 1000; std_time_ms = np.std(times) * 1000\n",
    "    logger.info(f\"‚úÖ {framework_name} Train Step Avg Time: {avg_time_ms:.3f} ¬± {std_time_ms:.3f} ms\")\n",
    "    return avg_time_ms, std_time_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Setup Optimizers & Criterion for Benchmark Execution ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1759521334.py:7] | \u001b[32m‚úÖ PyTorch optimizer and criterion ready for benchmark.\u001b[0m\n",
      "\u001b[32m2025-04-29 15:12:39\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1759521334.py:16] | \u001b[32m‚úÖ MLX optimizer ready for benchmark.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- PyTorch Optimizer & Criterion --- \n",
    "optimizer_pt = None\n",
    "criterion_pt = None\n",
    "if 'model_pt' in locals() and model_pt is not None:\n",
    "    optimizer_pt = optim_torch.AdamW(model_pt.parameters(), lr=1e-4) # Dummy LR for benchmark call\n",
    "    criterion_pt = nn.CrossEntropyLoss() \n",
    "    logger.info(\"‚úÖ PyTorch optimizer and criterion ready for benchmark.\")\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è PyTorch model not loaded, cannot create optimizer/criterion.\")\n",
    "\n",
    "# --- MLX Optimizer --- \n",
    "# (MLX criterion is embedded in loss_fn_mlx/grad_fn_mlx defined in Cell 8)\n",
    "optimizer_mlx = None\n",
    "if 'model_mlx' in locals() and model_mlx is not None:\n",
    "    optimizer_mlx = optim_mlx.AdamW(learning_rate=1e-4) # Dummy LR for benchmark call\n",
    "    logger.info(\"‚úÖ MLX optimizer ready for benchmark.\")\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è MLX model not loaded, cannot create optimizer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Execute Benchmarks üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:17:38\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:4] | \u001b[32m\n",
      "--- Benchmarking Forward Pass --- \u001b[0m\n",
      "\u001b[32m2025-04-29 15:17:38\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:6] | \u001b[32mRunning PyTorch Forward Benchmark...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:17:38\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:4] | \u001b[32m‚è±Ô∏è Benchmarking FORWARD pass (PyTorch on mps)...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:17:38\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:7] | \u001b[32m  üî• Performing 10 warmup runs...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:17:38\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:17] | \u001b[32m  üöÄ Performing 20000 benchmark runs...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:18:57\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:32] | \u001b[32m‚úÖ PyTorch Forward Avg Time: 3.965 ¬± 0.628 ms\u001b[0m\n",
      "\u001b[32m2025-04-29 15:18:57\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:11] | \u001b[32mRunning MLX Forward Benchmark...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:18:57\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:4] | \u001b[32m‚è±Ô∏è Benchmarking FORWARD pass (MLX on Device(gpu, 0))...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:18:57\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:7] | \u001b[32m  üî• Performing 10 warmup runs...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:18:57\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:17] | \u001b[32m  üöÄ Performing 20000 benchmark runs...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:20:33\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1822424293.py:32] | \u001b[32m‚úÖ MLX Forward Avg Time: 4.785 ¬± 0.492 ms\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:33\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:16] | \u001b[32m\n",
      "--- Benchmarking Training Step --- \u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:33\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:19] | \u001b[32mRunning PyTorch Training Step Benchmark...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:33\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:7] | \u001b[32m‚è±Ô∏è Benchmarking TRAIN step (PyTorch on mps)...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:33\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:19] | \u001b[32m  üî• Performing 5 warmup runs...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:20:34\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:39] | \u001b[32m  üöÄ Performing 100 benchmark runs...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 15:20:35\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:62] | \u001b[32m‚úÖ PyTorch Train Step Avg Time: 18.720 ¬± 0.808 ms\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:35\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1385460121.py:31] | \u001b[32mRunning MLX Training Step Benchmark...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:35\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:7] | \u001b[32m‚è±Ô∏è Benchmarking TRAIN step (MLX on Device(gpu, 0))...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:35\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mINFO    \u001b[0m | [1154224657.py:19] | \u001b[32m  üî• Performing 5 warmup runs...\u001b[0m\n",
      "\u001b[32m2025-04-29 15:20:35\u001b[0m | \u001b[34mBackprop Bunch\u001b[0m | \u001b[1;37mERROR   \u001b[0m | [1154224657.py:35] | \u001b[1;31m‚ùå Error during MLX warmup run 0: vector\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/s6/qfykwyn55ksgv8n9prqq55yc0000gq/T/ipykernel_23911/1154224657.py\", line 29, in benchmark_train_step\n",
      "    (loss, _), grads = mlx_grad_fn(model, data, labels) # Using _ for accuracy as it's not needed\n",
      "    ^^^^^^^^^\n",
      "IndexError: vector\n",
      "\n",
      "--- ‚úÖ Benchmark Results (Avg Time ms) ---\n",
      "üîπ PyTorch Forward : 3.965 ¬± 0.628\n",
      "üî∏ MLX Forward     : 4.785 ¬± 0.492\n",
      "------------------------------\n",
      "üîπ PyTorch Train Step: 18.720 ¬± 0.808\n",
      "üî∏ MLX Train Step  : N/A\n",
      "------------------------------\n",
      "üöÄ MLX Forward Speedup vs PyTorch: 0.83x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# --- Benchmark Forward Pass --- \n",
    "logger.info(\"\\n--- Benchmarking Forward Pass --- \")\n",
    "if 'model_pt' in locals() and model_pt is not None and 'images_pt' in locals() and images_pt is not None:\n",
    "    logger.info(\"Running PyTorch Forward Benchmark...\")\n",
    "    pt_fwd_results = benchmark_forward(model_pt, images_pt, pt_device, \"PyTorch\", num_runs=20000)\n",
    "    if pt_fwd_results: results['pt_forward_avg'], results['pt_forward_std'] = pt_fwd_results\n",
    "\n",
    "if 'model_mlx' in locals() and model_mlx is not None and 'images_mlx' in locals() and images_mlx is not None:\n",
    "    logger.info(\"Running MLX Forward Benchmark...\")\n",
    "    mlx_fwd_results = benchmark_forward(model_mlx, images_mlx, mlx_device, \"MLX\", num_runs=20000)\n",
    "    if mlx_fwd_results: results['mlx_forward_avg'], results['mlx_forward_std'] = mlx_fwd_results\n",
    "\n",
    "# --- Benchmark Training Step --- \n",
    "logger.info(\"\\n--- Benchmarking Training Step --- \")\n",
    "# Run PyTorch Benchmark\n",
    "if model_pt and optimizer_pt and criterion_pt and images_pt is not None and labels_pt is not None:\n",
    "    logger.info(\"Running PyTorch Training Step Benchmark...\")\n",
    "    pt_train_results = benchmark_train_step(\n",
    "        model=model_pt, data=images_pt, labels=labels_pt,\n",
    "        criterion=criterion_pt, optimizer=optimizer_pt, device=pt_device,\n",
    "        framework_name=\"PyTorch\", num_runs=100\n",
    "    )\n",
    "    if pt_train_results: results['pt_train_avg'], results['pt_train_std'] = pt_train_results\n",
    "else:\n",
    "    logger.warning(\"Skipping PyTorch training step benchmark - components not ready.\")\n",
    "\n",
    "# Run MLX Benchmark\n",
    "if model_mlx and optimizer_mlx and images_mlx is not None and labels_mlx is not None and 'loss_and_grad_fn_mlx' in locals() and loss_and_grad_fn_mlx is not None:\n",
    "    logger.info(\"Running MLX Training Step Benchmark...\")\n",
    "    mlx_train_results = benchmark_train_step(\n",
    "        model=model_mlx, data=images_mlx, labels=labels_mlx,\n",
    "        criterion=None, optimizer=optimizer_mlx, device=mlx_device,\n",
    "        framework_name=\"MLX\",\n",
    "        mlx_grad_fn=loss_and_grad_fn_mlx, # Pass grad fn\n",
    "        num_runs=100\n",
    "    )\n",
    "    if mlx_train_results: results['mlx_train_avg'], results['mlx_train_std'] = mlx_train_results\n",
    "else:\n",
    "    logger.warning(\"Skipping MLX training step benchmark - components not ready.\")\n",
    "\n",
    "# --- Print Summary --- \n",
    "print(\"\\n--- ‚úÖ Benchmark Results (Avg Time ms) ---\")\n",
    "def format_result(avg, std):\n",
    "    if isinstance(avg, (int, float)) and isinstance(std, (int, float)): return f\"{avg:.3f} ¬± {std:.3f}\"\n",
    "    else: return \"N/A\"\n",
    "print(f\"üîπ PyTorch Forward : {format_result(results.get('pt_forward_avg'), results.get('pt_forward_std'))}\")\n",
    "print(f\"üî∏ MLX Forward     : {format_result(results.get('mlx_forward_avg'), results.get('mlx_forward_std'))}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"üîπ PyTorch Train Step: {format_result(results.get('pt_train_avg'), results.get('pt_train_std'))}\")\n",
    "print(f\"üî∏ MLX Train Step  : {format_result(results.get('mlx_train_avg'), results.get('mlx_train_std'))}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Optional: Calculate speedup\n",
    "try:\n",
    "    pt_fwd=results.get('pt_forward_avg'); mlx_fwd=results.get('mlx_forward_avg')\n",
    "    if isinstance(pt_fwd, (int, float)) and isinstance(mlx_fwd, (int, float)) and mlx_fwd != 0: print(f\"üöÄ MLX Forward Speedup vs PyTorch: {pt_fwd / mlx_fwd:.2f}x\")\n",
    "    pt_train=results.get('pt_train_avg'); mlx_train=results.get('mlx_train_avg')\n",
    "    if isinstance(pt_train, (int, float)) and isinstance(mlx_train, (int, float)) and mlx_train != 0: print(f\"üöÄ MLX Train Step Speedup vs PyTorch: {pt_train / mlx_train:.2f}x\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate speedup: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion üèÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revised Conclusion from Benchmark:\n",
    "\n",
    "‚úÖ PyTorch completed both forward (~2.8ms) and training step (~19.7ms) benchmarks successfully.\n",
    "\n",
    "‚úÖ MLX completed the forward pass benchmark successfully (~4.8ms), showing it was slower than PyTorch for inference in this test.\n",
    "\n",
    "‚ùå MLX failed the training step benchmark due to a persistent IndexError: vector occurring during gradient computation via mx.grad / value_and_grad, preventing a direct speed comparison for training updates. This indicates a significant issue with using MLX's automatic differentiation with this specific ViT model structure on your system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
