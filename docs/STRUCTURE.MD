# MNIST Digit Classifier (Transformer) - Project Structure

This document outlines the detailed directory structure and the purpose of key files for the Week 3 MNIST Vision Transformer project by **Team Backprop Bunch**. The project aims to build and train a Vision Transformer model progressively across three phases.

## Directory Tree ğŸŒ³

```
ğŸ“ mlx-w3-mnist-transformer/
â”œâ”€â”€ ğŸ“ app/
â”‚ â””â”€â”€ ğŸ“„ init.py
â”œâ”€â”€ ğŸ“„ config.yaml # âš™ï¸ ViT configuration (phases, model, training)
â”œâ”€â”€ ğŸ“ data/ # ğŸ“Š MNIST dataset (auto-downloaded)
â”‚ â””â”€â”€ MNIST/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ raw/
â”œâ”€â”€ ğŸ³ Dockerfile
â”œâ”€â”€ ğŸ“ docs/ # ğŸ“„ Project documentation
â”‚ â”œâ”€â”€ ğŸ“„ 05_QKV.md # (Example Transformer Note)
â”‚ â”œâ”€â”€ (...) # (Other relevant general notes: 06-12)
â”‚ â””â”€â”€ ğŸ“„ STRUCTURE.MD # ğŸ‘ˆ This file
â”œâ”€â”€ ğŸ“ logs/ # ğŸ“ Runtime logs (e.g., mnist_vit_train.log)
â”œâ”€â”€ ğŸ“ models/ # ğŸ§  Saved model artifacts
â”‚ â””â”€â”€ ğŸ“ mnist_vit/ # Subdir for this project's models
â”‚ â”œâ”€â”€ ğŸ“ Phase1_E15_.../ # Example Phase 1 run output
â”‚ â”‚ â”œâ”€â”€ ğŸ“„ model_final.pth
â”‚ â”‚ â”œâ”€â”€ ...
â”‚ â””â”€â”€ ğŸ“ Phase2_E20_.../ # Example Phase 2 run output
â”‚ â”œâ”€â”€ ğŸ“„ model_final.pth
â”‚ â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ notebooks/ # ğŸ““ Jupyter notebooks
â”‚ â”œâ”€â”€ ğŸ“„ 01_mnist_vit_exploration.ipynb # EDA, Patching tests
â”‚ â”œâ”€â”€ ğŸ“„ 02_phase2_results_viz.ipynb # Visualization for Phase 2
â”‚ â””â”€â”€ ğŸ“„ 03_phase3_design_ideas.ipynb # Brainstorming for Phase 3
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“„ README.md # ğŸ‘‹ Project overview
â”œâ”€â”€ ğŸ“„ requirements.txt # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ“ scripts/ # â–¶ï¸ Runnable Python scripts
â”‚ â”œâ”€â”€ ğŸ“„ train_mnist_vit.py # ğŸ‘ˆ Main training script (handles phases)
â”‚ â”œâ”€â”€ ğŸ“„ evaluate.py # ğŸ‘ˆ Evaluation script
â”‚ â””â”€â”€ ğŸ“„ generate_project_doc.py # (Optional utility)
â”œâ”€â”€ ğŸ src/ # ğŸ Core Python source code
â”‚ â”œâ”€â”€ ğŸ“„ init.py
â”‚ â””â”€â”€ ğŸ“ mnist_transformer/ # ğŸ‘ˆ Module for ViT logic
â”‚ â”œâ”€â”€ ğŸ“„ init.py
â”‚ â”œâ”€â”€ ğŸ“„ dataset.py # ğŸ‘ˆ Handles MNIST (P1), 2x2 grid (P2), dynamic (P3)
â”‚ â”œâ”€â”€ ğŸ“„ modules.py # ğŸ‘ˆ ViT building blocks (PatchEmbed, Attention, MLP, EncoderBlock)
â”‚ â”œâ”€â”€ ğŸ“„ model.py # ğŸ‘ˆ Defines VisionTransformer class (adapts P1/P2/P3)
â”‚ â”œâ”€â”€ ğŸ“„ trainer.py # ğŸ‘ˆ Training/Eval loops (adapts loss/acc for P1/P2/P3)
â”‚ â””â”€â”€ ğŸ“„ evaluation.py # ğŸ‘ˆ (Optional) Metrics calculation functions
â”‚
â””â”€â”€ ğŸ› ï¸ utils/ # ğŸ› ï¸ Shared utility modules
â”œâ”€â”€ ğŸ“„ init.py
â”œâ”€â”€ ğŸ“„ device_setup.py
â”œâ”€â”€ ğŸ“„ logging.py
â””â”€â”€ ğŸ“„ run_utils.py
```


## Detailed Directory & File Descriptions ğŸ“œ

*   **Root Directory (`mlx-w3-mnist-transformer/`)**: Main project directory for the MNIST Vision Transformer.
    *   ğŸ“„ **`.gitignore`**: Lists files/dirs Git should ignore (e.g., `.venv`, `logs/`, `models/`, `wandb/`, `data/MNIST/`).
    *   ğŸ“„ **`config.yaml`** âš™ï¸: Central config for ViT project. Defines paths, dataset params (per phase), model hyperparameters (shared/phase-specific), training settings (per phase), evaluation, and logging.
    *   ğŸ“„ **`Dockerfile`** ğŸ³: (Optional) For building a Docker container.
    *   ğŸ“„ **`LICENSE`**: Project license.
    *   ğŸ“„ **`README.md`** ğŸ‘‹: High-level overview, setup, usage, status, and plan.
    *   ğŸ“„ **`requirements.txt`** ğŸ“¦: Python dependencies (`torch`, `torchvision`, `wandb`, `PyYAML`, `tqdm`, `coloredlogs`, etc.).

*   ğŸ“ **`app/`**: (Optional) For future API/UI deployment.
    *   ğŸ“„ **`__init__.py`**: Makes `app` a Python package.

*   ğŸ“ **`data/`** ğŸ“Š: Default location for datasets.
    *   ğŸ“ **`MNIST/`**: Auto-created by `torchvision` to store downloaded MNIST files. (Gitignored).

*   ğŸ“ **`docs/`** ğŸ“„: Project documentation and notes.
    *   ğŸ“„ `0X_*.md`: Conceptual notes on Transformers, ViT, etc.
    *   ğŸ“„ **`STRUCTURE.MD`**: This file, describing the project structure.
    *   ğŸ“„ **`DEV_PLAN_W3.md`**: Detailed development plan and task breakdown for Week 3.

*   ğŸ“ **`logs/`** ğŸ“: Stores runtime log files (e.g., `mnist_vit_train.log`). (Gitignored).

*   ğŸ“ **`models/`** ğŸ§ : Root directory for saved model artifacts. (Gitignored).
    *   ğŸ“ **`mnist_vit/`**: Contains subdirectories for trained MNIST ViT runs.
        *   ğŸ“ **`<RUN_NAME>/`**: Subdirectory for each training run (e.g., `Phase1_...`, `Phase2_...`). Contains saved model weights (`.pth`), loss data (`.json`), and plots (`.png`).

*   ğŸ“ **`notebooks/`** ğŸ““: Jupyter notebooks for exploration, visualization, and design.
    *   ğŸ“„ **`01_mnist_vit_exploration.ipynb`**: Initial EDA, patching tests.
    *   ğŸ“„ **`02_phase2_results_viz.ipynb`**: Visualization of Phase 2 model predictions.
    *   ğŸ“„ **`03_phase3_design_ideas.ipynb`**: Brainstorming and planning for Phase 3.

*   ğŸ“ **`scripts/`** â–¶ï¸: Main executable Python scripts.
    *   ğŸ“„ **`train_mnist_vit.py`**: Primary script for training the ViT model. Handles different phases via `--phase` argument, loads config, data, model, runs training loop, saves results, logs to W&B.
    *   ğŸ“„ **`evaluate.py`**: Script to load a saved model checkpoint and evaluate its performance on the appropriate test set (Phase 1 or Phase 2/3).
    *   ğŸ“„ `(Optional) generate_project_doc.py`: Utility for auto-documentation.

*   ğŸ“ **`src/`** ğŸ: Core source code modules.
    *   ğŸ“„ **`__init__.py`**: Makes `src` a Python package.
    *   ğŸ“ **`mnist_transformer/`** âœ¨: Core module for the ViT implementation.
        *   ğŸ“„ **`__init__.py`**: Marks `mnist_transformer` as a sub-package.
        *   ğŸ“„ **`dataset.py`**: Handles data loading (`get_mnist_dataset`), transformations (`get_mnist_transforms`), Phase 2 grid generation (`generate_2x2_grid_image`, `MNISTGridDataset`), and potentially Phase 3 dynamic data generation.
        *   ğŸ“„ **`modules.py`**: Defines ViT building blocks: `PatchEmbedding`, `Attention` (custom MHA using `AttentionHead`), `MLPBlock`, `TransformerEncoderBlock`.
        *   ğŸ“„ **`model.py`**: Defines the main `VisionTransformer` class, assembling modules and adapting for different phases (input size, output heads).
        *   ğŸ“„ **`trainer.py`**: Implements the training (`train_epoch`) and evaluation (`evaluate_model`) loops. Adapts loss and accuracy calculation based on the training phase. Contains the main `train_model` orchestrator.
        *   ğŸ“„ `(Optional) evaluation.py`: Could hold specific metric functions if needed.

*   ğŸ“ **`utils/`** ğŸ› ï¸: Shared utility modules.
    *   ğŸ“„ **`__init__.py`**: Marks `utils` as a package.
    *   ğŸ“„ **`device_setup.py`**: `get_device` function.
    *   ğŸ“„ **`logging.py`**: Configures the `Backprop Bunch` logger with colored console output.
    *   ğŸ“„ **`run_utils.py`**: Helper functions (`load_config`, `save_losses`, `plot_losses`).

*   ğŸ“ **`wandb/`** â˜ï¸: Local W&B cache and logs. (Gitignored).